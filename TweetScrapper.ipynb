{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9bef79",
   "metadata": {},
   "source": [
    "# Tweet Scraper\n",
    "\n",
    "Este es el notebook que usaremos para el scrapeo de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7eed62",
   "metadata": {},
   "source": [
    "## Librerias\n",
    "\n",
    "Para el scrapeo usaremos las siguientes librerias:\n",
    "* Sntwitter\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb93129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import snscrape.modules.twitter as snstwitter\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from JATS.src.JATS import JATS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3ab28",
   "metadata": {},
   "source": [
    "## Parametros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94327ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 2018-03-02\n",
      "0  /  -1\n",
      "2500  /  -1\n",
      "5000  /  -1\n",
      "7500  /  -1\n",
      "10000  /  -1\n",
      "12500  /  -1\n",
      "15000  /  -1\n",
      "17500  /  -1\n",
      "20000  /  -1\n",
      "22500  /  -1\n",
      "25000  /  -1\n",
      "27500  /  -1\n",
      "30000  /  -1\n",
      "32500  /  -1\n",
      "35000  /  -1\n",
      "37500  /  -1\n",
      "40000  /  -1\n",
      "42500  /  -1\n"
     ]
    }
   ],
   "source": [
    "query = '\"BTC\" OR \"bitcoin\"'\n",
    "\n",
    "date_from = datetime.date(2018, 3, 2)\n",
    "date_until = datetime.date(2018, 3, 3)\n",
    "\n",
    "tweet_list = JATS.get_tweets(query, date_from, date_until, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9cbdd8",
   "metadata": {},
   "source": [
    "### Lectura de ficheros ya existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(file_name, sep=',')\n",
    "\n",
    "tweet_df[\"Datetime\"] = pd.to_datetime(tweet_df[\"Datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa48d9",
   "metadata": {},
   "source": [
    "## Creación de nuevas columnas del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['sentiment'] = \"\"\n",
    "tweet_df['round_time'] = \"\"\n",
    "\n",
    "tweet_df[\"sentiment\"] = pd.to_numeric(tweet_df[\"sentiment\"])\n",
    "tweet_df[\"round_time\"] = pd.to_datetime(tweet_df[\"round_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563cabba",
   "metadata": {},
   "source": [
    "## Analisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29589f56",
   "metadata": {},
   "source": [
    "### Preparación del Analisis\n",
    "\n",
    "En caso de ser nuestra primera ejecución, deberemos instalar un conjunto de datasets utiles para *nltk*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e453004",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download([     \n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3032233",
   "metadata": {},
   "source": [
    "### Limpieza de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = emoji.get_emoji_regexp().sub(r'', tweet)\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922441f3-c2d2-432a-9517-bb95a7aa0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_round_time(data):\n",
    "    return data.replace(second=0, microsecond=0, minute=0)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "        Cleans and analyzes text.\n",
    "        \n",
    "        Parameters:\n",
    "        text(string): Bunch of text\n",
    "        \n",
    "        Returns:\n",
    "        Compound sentiment from NLTK polarity\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    clean_text = clean_tweet(text)\n",
    "    polarity = sia.polarity_scores(clean_text)\n",
    "    return polarity['compound']\n",
    "\n",
    "def prepare_data(tweet_df, verbose=False):\n",
    "    tweet_df['round_time'] = tweet_df['Datetime'].round('h')\n",
    "    \n",
    "    for index, row in tweet_df.iterrows():\n",
    "        tweet_df.loc[i, 'sentiment'] = get_sentiment(tweet_df['Text'].iloc[i])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c947f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prepare_data(tweet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50216e2c",
   "metadata": {},
   "source": [
    "## Analisis de Sentimiento\n",
    "\n",
    "Eliminaremos los valores nulos ya que parece que cuando el algoritmo no es capaz de determinar el sentimiento, tiende a ponerle un 0, creando una desviación del sentimiento real.\n",
    "\n",
    "Lo primero que haremos será mostrar la **media del sentimiento** y una **gráfica de distribución del sentimiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33111fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sentiment = tweet_df[tweet_df['sentiment'] != 0]['sentiment'].mean()\n",
    "\n",
    "print(f\"Average sentiment: {average_sentiment}\")\n",
    "\n",
    "sns.distplot(tweet_df[tweet_df['sentiment'] != 0]['sentiment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
