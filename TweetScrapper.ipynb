{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9bef79",
   "metadata": {},
   "source": [
    "# Tweet Scraper\n",
    "\n",
    "Este es el notebook que usaremos para el scrapeo de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7eed62",
   "metadata": {},
   "source": [
    "## Librerias\n",
    "\n",
    "Para el scrapeo usaremos las siguientes librerias:\n",
    "* Sntwitter\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb93129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import snscrape.modules.twitter as snstwitter\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3ab28",
   "metadata": {},
   "source": [
    "## Parametros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94327ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = [\n",
    "    'Datetime', 'Tweet Id', 'Text', \n",
    "    'NumReplies', 'NumRetweets', 'NumLikes', \n",
    "    'IDOriginalRetweeted', 'Username', 'isVerified'\n",
    "]\n",
    "\n",
    "condition_query = '\"BTC\" OR \"bitcoin\" since:{since} until:{until} lang:{lang}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d11bb",
   "metadata": {},
   "source": [
    "## Función obtener tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(date_from, date_until, tweet_limit = -1, lang=\"en\"):\n",
    "    \"\"\"\n",
    "        Función para scrapear tweets entre fechas\n",
    "        \n",
    "        Parameters:\n",
    "        date_from (datetime.date): Fecha de comienzo del scrapping\n",
    "        date_until (datetime.date): Fecha hasta la que se realiza el scrapping. Fecha no incluida.\n",
    "        tweet_limit (int): Limite de tweets al dia. -1 si no se quiere limite\n",
    "        \n",
    "        Returns:\n",
    "        Lista de Valores del tweet\n",
    "    \"\"\"\n",
    "    tweet_list = []\n",
    "    while(date_from != date_until):\n",
    "        print(\"Day \" + str(date_from))\n",
    "        a = datetime.datetime.now()\n",
    "\n",
    "        format_string = condition_query.format(\n",
    "            since=str(date_from),\n",
    "            until=str(date_from + timedelta(days=1)),\n",
    "            lang=lang\n",
    "        )\n",
    "        \n",
    "        for i, tweet in enumerate(snstwitter.TwitterSearchScraper(format_string).get_items()):\n",
    "            if i >= tweet_limit and tweet_limit != -1:\n",
    "                break\n",
    "                \n",
    "            if(i%2500==0):\n",
    "                print(i , \" / \" , tweet_limit)\n",
    "            \n",
    "            tweet_list.append(\n",
    "                [\n",
    "                    tweet.date, tweet.id, tweet.content,\n",
    "                    tweet.replyCount, tweet.retweetCount,\n",
    "                    tweet.likeCount, tweet.retweetedTweet,\n",
    "                    tweet.user.username, tweet.user.verified\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        date_from += timedelta(days=1)\n",
    "        b = datetime.datetime.now()\n",
    "        print(b-a)\n",
    "\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeadcf2",
   "metadata": {},
   "source": [
    "## Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a706a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_from = datetime.date(2018, 1, 1)\n",
    "date_until = datetime.date(2018, 2, 1)\n",
    "max_tweet = 1500\n",
    "\n",
    "directory = 'data/tweets/' + str(date_from) + '/' +  str(date_until)\n",
    "file_name = directory + '/tweet_list_' + str(max_tweet) +'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf17d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_list = get_tweets(date_from, date_until, tweet_limit = max_tweet)\n",
    "\n",
    "tweet_df = pd.DataFrame(tweet_list, columns=columnNames)\n",
    "del tweet_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a677760",
   "metadata": {},
   "source": [
    "### Escritura de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "tweet_df.to_csv(file_name, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925bc141",
   "metadata": {},
   "source": [
    "### Lectura de ficheros ya existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(file_name, sep=',')\n",
    "\n",
    "tweet_df[\"Datetime\"] = pd.to_datetime(tweet_df[\"Datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f96791",
   "metadata": {},
   "source": [
    "## Creación de nuevas columnas del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448bf9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['sentiment'] = \"\"\n",
    "tweet_df['round_time'] = \"\"\n",
    "\n",
    "tweet_df[\"sentiment\"] = pd.to_numeric(tweet_df[\"sentiment\"])\n",
    "tweet_df[\"round_time\"] = pd.to_datetime(tweet_df[\"round_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b3ff7",
   "metadata": {},
   "source": [
    "## Analisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567320c2",
   "metadata": {},
   "source": [
    "### Preparación del Analisis\n",
    "\n",
    "En caso de ser nuestra primera ejecución, deberemos instalar un conjunto de datasets utiles para *nltk*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c7e7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nltk.download([     \n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6933210",
   "metadata": {},
   "source": [
    "### Limpieza de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9319bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = emoji.get_emoji_regexp().sub(r'', tweet)\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "922441f3-c2d2-432a-9517-bb95a7aa0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_round_time(data):\n",
    "    return data.replace(second=0, microsecond=0, minute=0)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "        Cleans and analyzes text.\n",
    "        \n",
    "        Parameters:\n",
    "        text(string): Bunch of text\n",
    "        \n",
    "        Returns:\n",
    "        Compound sentiment from NLTK polarity\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    clean_text = clean_tweet(text)\n",
    "    polarity = sia.polarity_scores(clean_text)\n",
    "    return polarity['compound']\n",
    "\n",
    "def prepare_data(tweet_df, verbose=False):\n",
    "    tweet_df['round_time'] = tweet_df['Datetime'].round('h')\n",
    "    \n",
    "    for index, row in tweet_df.iterrows():\n",
    "        tweet_df.loc[i, 'sentiment'] = get_sentiment(tweet_df['Text'].iloc[i])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f778f13d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.763259172439575\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "prepare_data(tweet_df)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb57664",
   "metadata": {},
   "source": [
    "#### Timinng de las funciones\n",
    "\n",
    "iterrows . 20\n",
    ".map       27\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b27fae",
   "metadata": {},
   "source": [
    "## Analisis de Sentimiento\n",
    "\n",
    "Eliminaremos los valores nulos ya que parece que cuando el algoritmo no es capaz de determinar el sentimiento, tiende a ponerle un 0, creando una desviación del sentimiento real.\n",
    "\n",
    "Lo primero que haremos será mostrar la **media del sentimiento** y una **gráfica de distribución del sentimiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sentiment = tweet_df[tweet_df['sentiment'] != 0]['sentiment'].mean()\n",
    "\n",
    "print(f\"Average sentiment: {average_sentiment}\")\n",
    "\n",
    "sns.distplot(tweet_df[tweet_df['sentiment'] != 0]['sentiment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
