{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9bef79",
   "metadata": {},
   "source": [
    "# Tweet Scraper\n",
    "\n",
    "Este es el notebook que usaremos para el scrapeo de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7eed62",
   "metadata": {},
   "source": [
    "## Librerias\n",
    "\n",
    "Para el scrapeo usaremos las siguientes librerias:\n",
    "* Sntwitter\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb93129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import snscrape.modules.twitter as snstwitter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3ab28",
   "metadata": {},
   "source": [
    "## Parametros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94327ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = [\n",
    "    'Datetime', 'Tweet Id', 'Text', \n",
    "    'NumReplies', 'NumRetweets', 'NumLikes', \n",
    "    'IDOriginalRetweeted', 'Username', 'isVerified'\n",
    "]\n",
    "\n",
    "condition_query = '\"BTC\" OR \"bitcoin\" since:{since} until:{until} land:{lang}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d11bb",
   "metadata": {},
   "source": [
    "## Funci贸n obtener tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(date_from, date_until, max_tweets, lang=\"en\"):\n",
    "    \"\"\"\n",
    "        Funci贸n para scrapear tweets entre fechas\n",
    "        \n",
    "        Parameters:\n",
    "        date_from (datetime.date): Fecha de comienzo del scrapping\n",
    "        date_until (datetime.date): Fecha hasta la que se realiza el scrapping. Fecha no incluida.\n",
    "\n",
    "        Returns:\n",
    "        Lista de Valores del tweet\n",
    "    \"\"\"\n",
    "    tweet_list = []\n",
    "    while(date_from != date_until):\n",
    "        print(\"Day \" + str(date_from))\n",
    "        a = datetime.datetime.now()\n",
    "\n",
    "        format_string = condition_query.format(\n",
    "            since=str(date_from),\n",
    "            until=str(date_from + timedelta(days=1)),\n",
    "            lang=lang\n",
    "        )\n",
    "        \n",
    "        for i, tweet in enumerate(snstwitter.TwitterSearchScraper(format_string + \" lang:en\").get_items()):\n",
    "            if i>=max_tweets:\n",
    "                break\n",
    "            if(i%2500==0):\n",
    "                print(i , \" / \" , max_tweets)\n",
    "            \n",
    "            tweet_list.append(\n",
    "                [\n",
    "                    tweet.date, tweet.id, tweet.content,\n",
    "                    tweet.replyCount, tweet.retweetCount,\n",
    "                    tweet.likeCount, tweet.retweetedTweet,\n",
    "                    tweet.user.username, tweet.user.verified\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        date_from += timedelta(days=1)\n",
    "        b = datetime.datetime.now()\n",
    "        print(b-a)\n",
    "\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789240f",
   "metadata": {},
   "source": [
    "## Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a706a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_from = datetime.date(2021, 1, 1)\n",
    "date_until = datetime.date(2021, 1, 3)\n",
    "max_tweet = 3000\n",
    "\n",
    "directory = 'data/tweets/' + str(date_from) + '/' +  str(date_until)\n",
    "file_name = directory + '/tweet_list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = get_tweets(date_from, date_until, max_tweet)\n",
    "\n",
    "tweet_df = pd.DataFrame(tweet_list, columns=columnNames)\n",
    "del tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "tweet_df.to_csv(file_name, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc7aefa",
   "metadata": {},
   "source": [
    "### Lectura de ficheros ya existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9218c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(file_name, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb887ff",
   "metadata": {},
   "source": [
    "## Analisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e42903",
   "metadata": {},
   "source": [
    "### Preparaci贸n del Analisis\n",
    "\n",
    "En caso de ser nuestra primera ejecuci贸n, deberemos instalar un conjunto de datasets utiles para *nltk*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e0372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.download([     \n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9db690",
   "metadata": {},
   "source": [
    "### Limpieza de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fced73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = emoji.get_emoji_regexp().sub(r'', tweet)\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922441f3-c2d2-432a-9517-bb95a7aa0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_sentiment_summary(data = tweet_df, n=100, verbose=False):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    avg_sentiment = 0\n",
    "    for i in range(n):\n",
    "        tweet = tweet_df['Text'].iloc[i]\n",
    "        clean_tweet_str = clean_tweet(tweet)\n",
    "        polarity = sia.polarity_scores(clean_tweet_str)\n",
    "        \n",
    "        avg_sentiment += polarity['compound']\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n\")\n",
    "            print(f\"Before : \" + tweet)\n",
    "            print(f\"Afetr : \" +  clean_tweet_str) \n",
    "            print(polarity)\n",
    "            print(\"\\n\")\n",
    "            print(\"-\"*20)\n",
    "    return avg_sentiment/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweet_sentiment_summary(data = tweet_df, n=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
