{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9bef79",
   "metadata": {},
   "source": [
    "# Tweet Scraper\n",
    "\n",
    "Este es el notebook que usaremos para el scrapeo de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7eed62",
   "metadata": {},
   "source": [
    "## Librerias\n",
    "\n",
    "Para el scrapeo usaremos las siguientes librerias:\n",
    "* Sntwitter\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb93129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import snscrape.modules.twitter as snstwitter\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.JATS import JATS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3ab28",
   "metadata": {},
   "source": [
    "## Parametros\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5788a27f-4596-463e-ade2-9b92e4c87281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JATS.src.JATS.analyzer import Analyzer\n",
    "from nltk.corpus import stopwords\n",
    "a = Analyzer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd0d6e6-0072-4889-be01-96908620e0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, today I hate bitcoin products. Call Mark Tyson\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi, today I hate bitcoin and all their products. Call me Mark Tyson\"\n",
    "print(\" \".join([w for w in text.split() if not w in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec5debd-6242-4670-bf52-d829cb4d29ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.7 µs ± 847 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit text = \"Hi, today I hate bitcoin and all their products\"\n",
    "filtered_sentence = \" \".join([w for w in text.split() if not w in stop_words])\n",
    "\n",
    "a.get_sentiment(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb4e4a5-384e-421d-8e99-13e62b1b7f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 µs ± 975 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit text = \"Hi, today I hate bitcoin and all their products\"\n",
    "a.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94327ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = '\"BTC\" OR \"bitcoin\"'\n",
    "\n",
    "date_from = datetime.date(2018, 4, 1)\n",
    "date_until = datetime.date(2018, 4, 30)\n",
    "\n",
    "tweet_list = JATS.get_tweets(query, date_from, date_until, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3d038-e43a-4900-9418-c2a6e0d28800",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = [\n",
    "    'Datetime',\n",
    "    'Tweet Id',\n",
    "    'Text', \n",
    "    'NumReplies',\n",
    "    'NumRetweets',\n",
    "    'NumLikes', \n",
    "    'IDOriginalRetweeted', \n",
    "    'Username',\n",
    "    'isVerified'\n",
    "]\n",
    "tweet_df = pd.DataFrame(tweet_list, columns=columnNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9cbdd8",
   "metadata": {},
   "source": [
    "### Lectura de ficheros ya existentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d8f2a66",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/tweets/2018-04-01/2018-04-02/tweet_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-8b54a89df982>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/tweets/2018-04-01/2018-04-02/tweet_list.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtweet_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtweet_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Datetime\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Datetime\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Saturdays\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Saturdays\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Saturdays\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Saturdays\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Saturdays\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Saturdays\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Saturdays\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/tweets/2018-04-01/2018-04-02/tweet_list.csv'"
     ]
    }
   ],
   "source": [
    "file_name = \"data/tweets/2018-03-02/2018-04-03/tweet_list.csv\"\n",
    "tweet_df = pd.read_csv(file_name, sep=';')\n",
    "\n",
    "tweet_df[\"Datetime\"] = pd.to_datetime(tweet_df[\"Datetime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563cabba",
   "metadata": {},
   "source": [
    "## Analisis de sentimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29589f56",
   "metadata": {},
   "source": [
    "### Preparación del Analisis\n",
    "\n",
    "En caso de ser nuestra primera ejecución, deberemos instalar un conjunto de datasets utiles para *nltk*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e453004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JATS.src.JATS.analyzer import Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50216e2c",
   "metadata": {},
   "source": [
    "## Analisis de Sentimiento\n",
    "\n",
    "Eliminaremos los valores nulos ya que parece que cuando el algoritmo no es capaz de determinar el sentimiento, tiende a ponerle un 0, creando una desviación del sentimiento real.\n",
    "\n",
    "Lo primero que haremos será mostrar la **media del sentimiento** y una **gráfica de distribución del sentimiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "343e0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8112b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.analyze(tweet_df, \"data/tweets/2018-04-01/2018-04-02\") # Saved to a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd439c56-8346-41de-80a5-0efc9f96c27c",
   "metadata": {},
   "source": [
    "## Analisis de Similitudes\n",
    "\n",
    "Tenemos que comprobar la existencia de tweets similares para evitar el SPAM que existe en mensajes que no son completamente identicos.\n",
    "\n",
    "Para ellos haremos uso de la metrica de similitud Cosine Similarity y despues aplicaremos un DBScan para asignar clusters a esos tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92c1ce-3f42-478d-a687-4230483a5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_cosine_similarity(cleaned_texts):\n",
    "    vectorizer = CountVectorizer().fit_transform(cleaned_texts)\n",
    "    vectors = vectorizer.toarray()\n",
    "    return cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf97c6a-436e-48f7-8b45-a6a99fec5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tweet_df.isnull().sum())\n",
    "tweet_df = tweet_df.dropna(axis=0, subset=['Text'])\n",
    "print(tweet_df.isnull().sum())\n",
    "\n",
    "csim = get_cosine_similarity(tweet_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65785f54-c8a3-460b-925f-8941590960fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "clustering = DBSCAN(eps=1.04, min_samples=1).fit(csim)\n",
    "unique_elements, counts_elements = np.unique(clustering.labels_, return_counts=True)\n",
    "print(type(clustering.labels_))\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6099f2a-95f9-41d1-bd87-9f06cc796834",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a781c-e456-4774-9838-2f7e565c6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['Prediction'] = clustering.labels_.tolist()\n",
    "df = pd.DataFrame\n",
    "tweet_df[tweet_df['Prediction'] < 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86765b71-d1b4-4d78-ba9c-6203e83f9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column = [\"DateTime\",\"Cosa\"]\n",
    "df = pd.DataFrame(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c16c9a7-04b5-4d06-9f21-691463ddb172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DateTime</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  0\n",
       "0  DateTime  0\n",
       "1      Cosa  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee595e0-c7d9-4f5d-a1a1-a4ada7b4da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo: pass\n",
    "class Bar(Foo): pass\n",
    "class Bar2(Foo): pass\n",
    "class Bar(Bar): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3d5ec5-ebce-43ee-a4ba-ae5b1b79aa37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.Bar, __main__.Bar2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Foo.__subclasses__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2cbc5f5-d06e-4034-9a57-82cc0c0ad50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bar', 'Bar2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ q.__name__ for q in Foo.__subclasses__()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8112ea9f-b6dc-47d0-9e21-06d78ce84c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Bar at 0x241e1500af0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ q() for q in Foo.__subclasses__() if q.__name__ == \"Bar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5da2242c-37b2-4e9c-a67e-044eb356b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "d = {'col1': [1, 2,1,2,4,7,1], \n",
    "     'col2': [1, 2,1,1,4,1,1],\n",
    "     'col3': [11, 32,41,14,4,4,18],\n",
    "     'col5': ['11', '32','41','14','4','4','18']}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d47e0ee-a321-4ddb-98cc-9ef6a723a513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col1', 'col2', 'col3'], dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('col1', as_index=False).mean().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2073ae8f-103e-45f4-8784-2072b34dc93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
